{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-28T20:59:44.484354Z",
     "iopub.status.busy": "2025-10-28T20:59:44.484088Z",
     "iopub.status.idle": "2025-10-28T20:59:44.489203Z",
     "shell.execute_reply": "2025-10-28T20:59:44.488294Z",
     "shell.execute_reply.started": "2025-10-28T20:59:44.484337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "\n",
    "from scipy import linalg\n",
    "from sklearn.datasets import load_diabetes, make_regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV, Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import qr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Target-Aware ARS(Adaptive Residual Sampling) QRCP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T20:59:44.550229Z",
     "iopub.status.busy": "2025-10-28T20:59:44.549975Z",
     "iopub.status.idle": "2025-10-28T20:59:44.579179Z",
     "shell.execute_reply": "2025-10-28T20:59:44.578232Z",
     "shell.execute_reply.started": "2025-10-28T20:59:44.550211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Scikit-Learn Style Class of TAAQ\n",
    "class TAAQ:\n",
    "    \"\"\"\n",
    "    Target-Aware ARS-QRCP (TAAQ) Feature Selection\n",
    "\n",
    "    3-Phase Algorithm:\n",
    "    - Phase 1: QRCP warm-up for k1\n",
    "    - Phase 2: Target-Projected Residual Sampling (TPRS) with one-step deflation\n",
    "    - Phase 3: Geometry-Predictive Pruning to size k\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k: int, k1_fraction: float = 0.5, delta: int = 10,\n",
    "                epsilon: float = 1e-6, supervised: bool = True):\n",
    "        self.k = k\n",
    "        self.k1_fraction = k1_fraction\n",
    "        self.delta = delta\n",
    "        self.epsilon = epsilon\n",
    "        self.supervised = supervised\n",
    "        self.selected_features_ = None\n",
    "        self.runtime_ = {}\n",
    "\n",
    "    def fit(self, M: np.ndarray, y:np.ndarray) -> 'TAAQ':\n",
    "        \"\"\"\n",
    "        Fit TAAQ Selector (Model Trainer)\n",
    "        \"\"\"\n",
    "\n",
    "        # Stamp the start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Preprocessing\n",
    "        M_std, y_std = self._preprocess(M, y)\n",
    "        m, n = M_std.shape\n",
    "\n",
    "        # Phase1: QRCP warm-up\n",
    "        t1 = time.time()\n",
    "        k1 = int(self.k * self.k1_fraction)\n",
    "        Q1, R11, S1 = self._phase1_qrcp(M_std, k1)\n",
    "        # Q1, R11, S1 = self._phase1_partial_qrcp(M_std, k1)\n",
    "        self.runtime_['phase1'] = time.time() - t1\n",
    "\n",
    "        # Phase2: TPRS (Target-Projected Residual Sampling)\n",
    "        t2 = time.time()\n",
    "        S2_prime = self._phase2_tprs(M_std, y_std, Q1, S1, k1, self.delta)\n",
    "        self.runtime_['phase2'] = time.time() - t2\n",
    "\n",
    "        # Phase3: GPP (Geometry-Predictive Pruning)\n",
    "        t3 = time.time()\n",
    "        S_tmp = np.concatenate([S1, S2_prime])\n",
    "        S_final = self._phase3_gpp(M_std, y_std, S_tmp, self.k)\n",
    "        self.runtime_['phase3'] = time.time() - t3\n",
    "\n",
    "        self.selected_features_ = S_final\n",
    "        self.runtime_['total'] = time.time() - start_time\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _preprocess(self, M: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Standardize columns of M and scale y.\n",
    "        \"\"\"\n",
    "        m, n = M.shape\n",
    "\n",
    "        # Standardize columns (axis=0): zero mean, unit variance\n",
    "        M_std = (M - M.mean(axis=0, keepdims=True)) / (M.std(axis=0, keepdims=True) + 1e-10)\n",
    "\n",
    "        # Center and scale y so that ||y||_2^2 = m\n",
    "        y_mean = y.mean()\n",
    "        y_sd = y.std()\n",
    "        y_std = (y - y_mean) / (y_sd + 1e-10)\n",
    "\n",
    "        return M_std, y_std\n",
    "\n",
    "    def _phase1_qrcp(self, M: np.ndarray, k1: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        _, R, piv = linalg.qr(M, mode='economic', pivoting=True)\n",
    "\n",
    "        S1 = piv[:k1]\n",
    "\n",
    "        Q1, R11 = linalg.qr(M[:, S1], mode='economic')\n",
    "\n",
    "        return Q1, R11, S1\n",
    "\n",
    "    def _phase1_partial_qrcp(self, M: np.ndarray, k1: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Phase 1: Highly optimized Partial QRCP (k1 steps only).\n",
    "\n",
    "        Complexity: O(m*n*k1)\n",
    "        \"\"\"\n",
    "         \n",
    "        m, n = M.shape\n",
    "        \n",
    "        # Working copy\n",
    "        A = M.copy()\n",
    "        \n",
    "        # perm tracks the original column indices.\n",
    "        # perm[k] will store the original index of the k-th pivot column.\n",
    "        perm = np.arange(n)\n",
    "        \n",
    "        # Pre-compute the squared L2-norm of each column for pivoting.\n",
    "        # We use squared norms to avoid sqrt.\n",
    "        col_norms_full = np.sum(A**2, axis=0)\n",
    "        col_norms_partial = col_norms_full.copy()\n",
    "        \n",
    "        # Storage for the 'tau' scalars needed to reconstruct Q.\n",
    "        # H_k = I - tau_scalars[k] * v_k * v_k^T\n",
    "        tau_scalars = np.zeros(k1)\n",
    "\n",
    "        # main loop\n",
    "        for k in range(k1):\n",
    "            \n",
    "            # ====================\n",
    "            # 1. COLUMN PIVOTING\n",
    "            # ====================\n",
    "            # Find the column with the maximum remaining norm in the sub-array A[k:, k:].\n",
    "            j_max = k + np.argmax(col_norms_partial[k:])\n",
    "            \n",
    "            if j_max != k:\n",
    "                # Swap the pivot column (j_max) with the current column (k)\n",
    "                A[:, [k, j_max]] = A[:, [j_max, k]]\n",
    "                perm[[k, j_max]] = perm[[j_max, k]]\n",
    "                col_norms_full[[k, j_max]] = col_norms_full[[j_max, k]]\n",
    "                col_norms_partial[[k, j_max]] = col_norms_partial[[j_max, k]]\n",
    "            \n",
    "            # ========================================\n",
    "            # 2. HOUSEHOLDER QR STEP (on column k)\n",
    "            # ========================================\n",
    "            \n",
    "            # Get the k-th column vector starting from the diagonal.\n",
    "            x_k = A[k:m, k]\n",
    "            norm_x_k = np.linalg.norm(x_k)\n",
    "\n",
    "            if norm_x_k < 1e-14:\n",
    "                # This column is already (numerically) zero.\n",
    "                # No reflection needed.\n",
    "                tau_scalars[k] = 0\n",
    "                continue\n",
    "            \n",
    "            # 'sigma_k' is the target value for the first element,\n",
    "            # sign((x_k)_1) * ||x_k||.\n",
    "            sigma_k = -np.sign(x_k[0]) * norm_x_k if x_k[0] != 0 else -norm_x_k\n",
    "            \n",
    "            # --- Calculate the LAPACK-style Householder vector 'v' and 'tau' ---\n",
    "            \n",
    "            # 1. u_k = x_k - sigma_k * e_1\n",
    "            u_0 = x_k[0] - sigma_k\n",
    "            u_tail = x_k[1:]\n",
    "            \n",
    "            # 2. tau_k = -u_0 / sigma_k\n",
    "            tau_k = -u_0 / sigma_k\n",
    "            tau_scalars[k] = tau_k # Store for Q reconstruction\n",
    "            \n",
    "            # 3. v_k = u_k / u_0 = [1, u_tail / u_0]^T\n",
    "            v_tail = u_tail / u_0 if u_0 != 0 else u_tail # Avoid division by zero\n",
    "\n",
    "            # Apply the reflection H_k to all remaining columns (k+1 to n)\n",
    "            # A_sub = (I - tau_k * v_k * v_k^T) @ A_sub\n",
    "            if k < n - 1:\n",
    "                A_sub = A[k:m, k+1:n]\n",
    "                A_sub_head = A_sub[0, :]     # First row of the submatrix\n",
    "                A_sub_tail = A_sub[1:, :]    # Rest of the submatrix\n",
    "                \n",
    "                # w = (v_k^T @ A_sub)\n",
    "                #   = (v_k[0] * A_sub_head) + (v_tail^T @ A_sub_tail)\n",
    "                #   = (1 * A_sub_head) + (v_tail^T @ A_sub_tail)\n",
    "                w = A_sub_head + (v_tail @ A_sub_tail)\n",
    "                \n",
    "                # A_sub = A_sub - tau_k * v_k * w^T\n",
    "                A[k, k+1:n] -= tau_k * w              # Update head (v_k[0]=1)\n",
    "                A[k+1:m, k+1:n] -= tau_k * np.outer(v_tail, w) # Update tail\n",
    "            \n",
    "            # Store R_kk and the Householder vector v_tail\n",
    "            # directly into the matrix A.\n",
    "            A[k, k] = sigma_k      # R's diagonal element\n",
    "            A[k+1:m, k] = v_tail # The tail of the vector v_k\n",
    "            \n",
    "            # ===================================\n",
    "            # 3. UPDATE COLUMN NORMS (downdate)\n",
    "            # ===================================\n",
    "            # This is the O(n) part.\n",
    "            # Use Pythagoras to update the remaining norm of each column after the reflection.\n",
    "            # new_tail_norm^2 = total_norm^2 - new_head_val^2\n",
    "            if k < n - 1:\n",
    "                for j in range(k+1, n):\n",
    "                    # temp = 1 - (A[k, j] / col_norms_partial[j])**2\n",
    "                    temp_ratio = A[k, j] / col_norms_partial[j] if col_norms_partial[j] > 0 else 0\n",
    "                    temp_ratio = max(0, (1 - temp_ratio) * (1 + temp_ratio)) # (1-t^2)\n",
    "                    \n",
    "                    # col_norms_partial[j] = col_norms_partial[j] * sqrt(temp_ratio)\n",
    "                    col_norms_partial[j] *= np.sqrt(temp_ratio)\n",
    "                    \n",
    "                    # Failsafe: Recompute norm if numerical error accumulates\n",
    "                    if col_norms_partial[j] < 0.1 * np.sqrt(col_norms_full[j]):\n",
    "                        col_norms_partial[j] = np.linalg.norm(A[k+1:m, j])\n",
    "                        col_norms_full[j] = col_norms_partial[j]**2\n",
    "        \n",
    "        # ====================================================================\n",
    "        # 4. EXTRACT RESULTS (Q, R, S)\n",
    "        # ====================================================================\n",
    "        \n",
    "        # R11 is the upper-triangular k1 x k1 block of A\n",
    "        R11 = np.triu(A[:k1, :k1])\n",
    "\n",
    "        Q1 = np.eye(m, k1)\n",
    "        \n",
    "        for k in range(k1-1, -1, -1):\n",
    "            tau_k = tau_scalars[k] # Get the stored scalar\n",
    "            \n",
    "            if tau_k != 0:\n",
    "                # Reconstruct v_k = [1, v_tail]^T\n",
    "                v = np.zeros(m - k)\n",
    "                v[0] = 1\n",
    "                v[1:] = A[k+1:m, k] # Get the stored v_tail\n",
    "                \n",
    "                # Apply the transformation:\n",
    "                # Q1[k:, k:] = H_k @ Q1[k:, k:]\n",
    "                #            = (I - tau_k * v * v^T) @ Q1[k:, k:]\n",
    "                w = tau_k * (v @ Q1[k:, k:])\n",
    "                Q1[k:, k:] -= np.outer(v, w)\n",
    "        \n",
    "        # S1: The original indices of the first k1 pivot columns\n",
    "        S1 = perm[:k1]\n",
    "        \n",
    "        return Q1, R11, S1\n",
    "    \n",
    "    def _phase2_tprs(self, M: np.ndarray, y: np.ndarray, Q1: np.ndarray,\n",
    "                    S1: np.ndarray, k1: int, delta: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Phase 2: Target-Projected Residual Sampling with one-step \n",
    "        \"\"\"\n",
    "        m, n = M.shape\n",
    "        k2 = self.k - k1\n",
    "        # ==========\n",
    "        # 1. TPRS\n",
    "        # ==========\n",
    "        # Target residual\n",
    "        r_y = y - Q1 @ (Q1.T @ y)\n",
    "\n",
    "        # Precompute residualized features\n",
    "        Q1_T_M = Q1.T @ M\n",
    "\n",
    "        # b_j = \\|x_j\\|_2^2 - \\|Q_1^Tx_j\\|_2^2\n",
    "        b = np.sum(M**2, axis=0) - np.sum(Q1_T_M**2, axis=0)\n",
    "        b = np.maximum(b, self.epsilon) # Prevent 0\n",
    "\n",
    "        # s_j = r_y^TP_\\perpx_j = r_y^Tx_j\n",
    "        s = r_y @ M\n",
    "\n",
    "        # Supervised score a_j := s_j^2 / (b_j + \\epsilon)\n",
    "        if self.supervised:\n",
    "            a = s**2 / (b + self.epsilon)\n",
    "        else:\n",
    "            a = b\n",
    "        # ==================================================\n",
    "        # 2. Greedy Oversampling with one-step deflation\n",
    "        # ==================================================\n",
    "                \n",
    "        # Initialize candidate pool\n",
    "        valid_mask = np.ones(n, dtype=bool)\n",
    "        valid_mask[S1] = False\n",
    "\n",
    "        # List for chosen columns in phase 2\n",
    "        S2_prime = []\n",
    "\n",
    "        for _ in range(k2+delta):\n",
    "            a_masked = np.where(valid_mask, a, -np.inf)\n",
    "\n",
    "            # j* = argmax a_j\n",
    "            j_star = np.argmax(a_masked)\n",
    "\n",
    "            # Add it to the answer\n",
    "            S2_prime.append(j_star)\n",
    "\n",
    "            # Update for the next iteration\n",
    "            valid_mask[j_star] = False\n",
    "\n",
    "            # ----- One-Step Deflation ----- #\n",
    "\n",
    "            # Choose the column for the chosen j\n",
    "            x_j = M[:, j_star]\n",
    "\n",
    "            # Get P_\\perp x_j\n",
    "            P_perp_x = x_j - Q1 @ (Q1.T @ x_j)\n",
    "\n",
    "            # Normalize it\n",
    "            norm_P_perp_x = np.linalg.norm(P_perp_x)\n",
    "\n",
    "            if norm_P_perp_x > 1e-10:\n",
    "\n",
    "                # New direction (contribution) of x_j\n",
    "                u = P_perp_x / norm_P_perp_x\n",
    "\n",
    "                # The Magnitude * direction = The new contribution of x_j\n",
    "                g = u.T @ M\n",
    "\n",
    "                # The new columns contribution to the label\n",
    "                alpha = u.T @ r_y\n",
    "\n",
    "                # Decrease the residual\n",
    "                r_y -= alpha * u\n",
    "\n",
    "                # Decrease the correlation of each columns\n",
    "                s -= alpha * g\n",
    "\n",
    "                if self.supervised:\n",
    "                    a = s**2 / (b+self.epsilon)\n",
    "\n",
    "                else:\n",
    "                    a = b     \n",
    "\n",
    "        return np.array(S2_prime, dtype=int)\n",
    "\n",
    "    def _phase3_gpp(self, M: np.ndarray, y: np.ndarray,\n",
    "                   S_tmp: np.ndarray, k:int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Phase 3: Geometry-Predictive Pruning to size k.\n",
    "        \"\"\"\n",
    "        # Working copy\n",
    "        S_current = S_tmp.copy()\n",
    "\n",
    "        # Measure delta that we are going to prune\n",
    "        delta = len(S_tmp) - k\n",
    "\n",
    "        for _ in range(delta):\n",
    "            C = M[:, S_current]\n",
    "\n",
    "            # QR Decomposition\n",
    "            # mode='economic' --> thin QR (Q = m*n, R = n*n)\n",
    "            Q, R = linalg.qr(C, mode='economic')\n",
    "\n",
    "            # Compute beta (R^-1(Q^T y)) --> \"Predictive\"\n",
    "            # We don't get inverse, we use \"back substitution\" (solve_triangular)\n",
    "            # \\beta = min\\|C\\beta-y\\|_2^2\n",
    "            # Least Square Problem\n",
    "            # Equation: C\\beta = y\n",
    "            # Solution: \\beta = (C^TC)^-1C^Ty\n",
    "            # \\beta = (R^TQ^TQ^R)^-1R^TQ^Ty = (R^TR)^-1R^TQ^Ty = R^-1Q^Ty\n",
    "            beta = linalg.solve_triangular(R, Q.T @ y, lower=False)\n",
    "\n",
    "            # Compute r_i --> \"Geometric Redundancy\" (Numerical Instability)\n",
    "            # VIF (Variance Inflaction Factor) = 1/ (1 - R_i)\n",
    "            # C = QR --> G = C^TC = R^TR\n",
    "            # r_i = \\|R^-Te_i\\|_2^2 = (R^-Te_i)^T(R^-Te_i) = e_i^T(R^-1R^-T)e_i = e_i^T(R^TR)^-1e_i = [(C^TC)^-1]_ii\n",
    "            # By block matrix inversion --> (G^-1)_ii = 1 / c_i^Tc_i(1-R_i^2) = 1/\\|c_i\\|_2^2 \\times VIF_i\n",
    "            R_inv_T = linalg.solve_triangular(R, np.eye(len(S_current)), trans='T', lower=False)\n",
    "            r_i = np.sum(R_inv_T**2, axis=0)\n",
    "\n",
    "            # Compute drop scores: d_i = r_i / (beta_i^2 + epsilon)\n",
    "            d_i = r_i / (beta**2 + self.epsilon)\n",
    "\n",
    "            # Remove worst feature\n",
    "            i_star = np.argmax(d_i)\n",
    "            S_current = np.delete(S_current, i_star) # Delete the column\n",
    "\n",
    "        return S_current\n",
    "        \n",
    "    def transform(self, M: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Select features from M.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.selected_features_ is None:\n",
    "            raise ValueError(\"Must fit before transform\")\n",
    "            \n",
    "        return M[:, self.selected_features_]  \n",
    "        \n",
    "    def fit_transform(self, M: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fit and transform in one step.\n",
    "        \"\"\"\n",
    "        return self.fit(M, y).transform(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Baseline Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T20:59:44.580670Z",
     "iopub.status.busy": "2025-10-28T20:59:44.580456Z",
     "iopub.status.idle": "2025-10-28T20:59:44.601062Z",
     "shell.execute_reply": "2025-10-28T20:59:44.600118Z",
     "shell.execute_reply.started": "2025-10-28T20:59:44.580654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import qr\n",
    "class QRCP:\n",
    "    \"\"\"\n",
    "    QR Decomposition with Column Pivoting (QRCP) \n",
    "\n",
    "    Produces a weak rank-revealing decomposition:\n",
    "        X[:, P] = Q @ R\n",
    "    where:\n",
    "        - Q is orthogonal\n",
    "        - R is upper-triangular\n",
    "        - P is a permutation array (pivot indices)\n",
    "    \n",
    "    Can select the top-k columns based on pivoting.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, top_k: int = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        top_k : int, optional\n",
    "            Number of top features (columns) to select. If None, select all.\n",
    "        \"\"\"\n",
    "        self.top_k = top_k                # Target number of features\n",
    "        self.Q = None                     # Orthogonal matrix from QR\n",
    "        self.R = None                     # Upper-triangular matrix from QR\n",
    "        self.P = None                     # Column permutation indices\n",
    "        self.selected_features_ = None    # Indices of top-selected features\n",
    "        self.runtime_ = {}                # Dictionary to track runtimes\n",
    "\n",
    "    def fit(self, X: np.ndarray, y=None) -> 'QRCP':\n",
    "        \"\"\"\n",
    "        Fit the QRCP model to the data X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray, shape (m, n)\n",
    "            Input feature matrix\n",
    "        y : ignored\n",
    "            Included for API compatibility with supervised methods.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : QRCP\n",
    "            Fitted object with Q, R, P, and selected_features_ populated.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        # STEP 1: Compute QR decomposition with column pivoting\n",
    "        t_qr_start = time.time()\n",
    "        Q, R, piv = qr(X, pivoting=True, mode='economic')\n",
    "        self.runtime_['qr_decomposition'] = time.time() - t_qr_start\n",
    "\n",
    "        # Store decomposition results\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "        self.P = np.array(piv)\n",
    "\n",
    "        # STEP 2: Determine selected features (top-k pivoted columns)\n",
    "        n_features = X.shape[1]\n",
    "        k = self.top_k if self.top_k is not None else n_features\n",
    "        self.selected_features_ = self.P[:k]\n",
    "\n",
    "        # Record total runtime\n",
    "        self.runtime_['total'] = time.time() - start_time\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transform X by selecting the top-k pivoted columns.\n",
    "        \"\"\"\n",
    "        if self.selected_features_ is None:\n",
    "            raise ValueError(\"Must call fit() before transform()\")\n",
    "        return X[:, self.selected_features_]\n",
    "\n",
    "    def fit_transform(self, X: np.ndarray, y=None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convenience method to fit and transform in one step.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluation Framework (Metric, Plotting, Tracks)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T20:59:44.602390Z",
     "iopub.status.busy": "2025-10-28T20:59:44.602159Z",
     "iopub.status.idle": "2025-10-28T20:59:44.622713Z",
     "shell.execute_reply": "2025-10-28T20:59:44.622040Z",
     "shell.execute_reply.started": "2025-10-28T20:59:44.602372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bar_plot(scores: Dict[str, float], title: str, ylabel: str):\n",
    "    labels = list(scores.keys())\n",
    "    vals = [scores[k] for k in labels]\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.bar(labels, vals)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_supervised_track(X: np.ndarray, y: np.ndarray, k: int, n_splits: int = 3):\n",
    "    print(\"\\n\" + \"=\"*68)\n",
    "    print(\"TRACK A — SUPERVISED  (TAAQ  vs  QRCP)\")\n",
    "    print(\"=\"*68)\n",
    "\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    ys = (y - y.mean()) / (y.std() + 1e-12)\n",
    "\n",
    "    methods = {\n",
    "        \"TAAQ\": TAAQ(k=k, k1_fraction=0.5, delta=10, supervised=True),\n",
    "        \"QRCP\": QRCP(top_k=k), \n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    rows = []\n",
    "    for fold, (tr, te) in enumerate(kf.split(Xs)):\n",
    "        Xtr, Xte = Xs[tr], Xs[te]\n",
    "        ytr, yte = ys[tr], ys[te]\n",
    "        print(f\"\\n  Fold {fold+1}/{n_splits}\")\n",
    "        for name, meth in methods.items():\n",
    "            t = time.time()\n",
    "            meth.fit(Xtr, ytr)\n",
    "            S = meth.selected_features_\n",
    "            # Ridge on selected features (held-out test)\n",
    "            mdl = Ridge(alpha=1.0).fit(Xtr[:, S], ytr)\n",
    "            y_pred = mdl.predict(Xte[:, S])\n",
    "            r2 = r2_score(yte, y_pred)\n",
    "            rmse = float(np.sqrt(mean_squared_error(yte, y_pred)))\n",
    "            runtime = time.time() - t\n",
    "            rows.append(dict(method=name, fold=fold, r2=r2, rmse=rmse, runtime=runtime, k=len(S)))\n",
    "            print(f\"    - {name:6s} | R²={r2: .3f} | RMSE={rmse: .3f} | k={len(S)}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    summ = df.groupby(\"method\")[[\"r2\", \"rmse\", \"runtime\"]].mean().round(4)\n",
    "    print(\"\\nSupervised summary (mean over folds):\\n\", summ)\n",
    "\n",
    "    bar_plot(summ[\"r2\"].to_dict(), \"Supervised: R² (higher is better)\", \"R²\")\n",
    "    bar_plot(summ[\"rmse\"].to_dict(), \"Supervised: RMSE (lower is better)\", \"RMSE\")\n",
    "    bar_plot(summ[\"runtime\"].to_dict(), \"Supervised: Runtime (s)\", \"seconds\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Data Generators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T20:59:44.624363Z",
     "iopub.status.busy": "2025-10-28T20:59:44.624151Z",
     "iopub.status.idle": "2025-10-28T20:59:44.644773Z",
     "shell.execute_reply": "2025-10-28T20:59:44.643819Z",
     "shell.execute_reply.started": "2025-10-28T20:59:44.624349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dataset_synthetic(m=350, n=120, k_true=25, noise=10, seed=42):\n",
    "    X, y = make_regression(n_samples=m, n_features=n, n_informative=k_true,\n",
    "                           noise=noise, random_state=seed)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T20:59:44.645841Z",
     "iopub.status.busy": "2025-10-28T20:59:44.645605Z",
     "iopub.status.idle": "2025-10-28T20:59:44.663953Z",
     "shell.execute_reply": "2025-10-28T20:59:44.663223Z",
     "shell.execute_reply.started": "2025-10-28T20:59:44.645826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TAAQ MINIMAL EXPERIMENTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 1) Synthetic: both tracks\n",
    "    print(\"\\n[Dataset] Synthetic linear (m=350, n=120)\")\n",
    "    Xs, ys = dataset_synthetic()\n",
    "    k = 35\n",
    "    run_supervised_track(Xs, ys, k=k, n_splits=3)\n",
    "\n",
    "    print(\"\\nAll done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Quick Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Main Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T20:59:44.665064Z",
     "iopub.status.busy": "2025-10-28T20:59:44.664814Z",
     "iopub.status.idle": "2025-10-28T20:59:45.341260Z",
     "shell.execute_reply": "2025-10-28T20:59:45.340197Z",
     "shell.execute_reply.started": "2025-10-28T20:59:44.665044Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TAAQ MINIMAL EXPERIMENTS\n",
      "================================================================================\n",
      "\n",
      "[Dataset] Synthetic linear (m=350, n=120)\n",
      "\n",
      "====================================================================\n",
      "TRACK A — SUPERVISED  (TAAQ  vs  QRCP)\n",
      "====================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m Xs, ys = dataset_synthetic()\n\u001b[32m      9\u001b[39m k = \u001b[32m35\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mrun_supervised_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll done.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mrun_supervised_track\u001b[39m\u001b[34m(X, y, k, n_splits)\u001b[39m\n\u001b[32m     25\u001b[39m kf = KFold(n_splits=n_splits, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     26\u001b[39m rows = []\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m Xtr, Xte = Xs[\u001b[43mtr\u001b[49m], Xs[te]\n\u001b[32m     28\u001b[39m ytr, yte = ys[tr], ys[te]\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_splits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
