{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "\n",
    "from scipy import linalg\n",
    "from sklearn.datasets import load_diabetes, make_regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV, Ridge, ElasticNetCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from mrmr import mrmr_regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Target-Aware ARS(Adaptive Residual Sampling) QRCP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn Style Class of TAAQ\n",
    "class TAAQ:\n",
    "    \"\"\"\n",
    "    Target-Aware ARS-QRCP (TAAQ) Feature Selection\n",
    "\n",
    "    3-Phase Algorithm:\n",
    "    - Phase 1: QRCP warm-up for k1\n",
    "    - Phase 2: Target-Projected Residual Sampling (TPRS) with one-step deflation\n",
    "    - Phase 3: Geometry-Predictive Pruning to size k\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k: int, k1_fraction: float = 0.5, delta: int = 10,\n",
    "                epsilon: float = 1e-6, supervised: bool = True):\n",
    "        self.k = k\n",
    "        self.k1_fraction = k1_fraction\n",
    "        self.delta = delta\n",
    "        self.epsilon = epsilon\n",
    "        self.supervised = supervised\n",
    "        self.selected_features_ = None\n",
    "        self.runtime_ = {}\n",
    "\n",
    "    def fit(self, M: np.ndarray, y:np.ndarray) -> 'TAAQ':\n",
    "        \"\"\"\n",
    "        Fit TAAQ Selector (Model Trainer)\n",
    "        \"\"\"\n",
    "\n",
    "        # Stamp the start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Preprocessing\n",
    "        M_std, y_std = self._preprocess(M, y)\n",
    "        m, n = M_std.shape\n",
    "\n",
    "        # Phase1: QRCP warm-up\n",
    "        t1 = time.time()\n",
    "        k1 = int(self.k * self.k1_fraction)\n",
    "        Q1, R11, S1 = self._phase1_qrcp(M_std, k1)\n",
    "        # Q1, R11, S1 = self._phase1_partial_qrcp(M_std, k1)\n",
    "        self.runtime_['phase1'] = time.time() - t1\n",
    "\n",
    "        # Phase2: TPRS (Target-Projected Residual Sampling)\n",
    "        t2 = time.time()\n",
    "        S2_prime = self._phase2_tprs(M_std, y_std, Q1, S1, k1, self.delta)\n",
    "        self.runtime_['phase2'] = time.time() - t2\n",
    "\n",
    "        # Phase3: GPP (Geometry-Predictive Pruning)\n",
    "        t3 = time.time()\n",
    "        S_tmp = np.concatenate([S1, S2_prime])\n",
    "        S_final = self._phase3_gpp(M_std, y_std, S_tmp, self.k)\n",
    "        self.runtime_['phase3'] = time.time() - t3\n",
    "\n",
    "        self.selected_features_ = S_final\n",
    "        self.runtime_['total'] = time.time() - start_time\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _preprocess(self, M: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Standardize columns of M and scale y.\n",
    "        \"\"\"\n",
    "        m, n = M.shape\n",
    "\n",
    "        # Standardize columns (axis=0): zero mean, unit variance\n",
    "        M_std = (M - M.mean(axis=0, keepdims=True)) / (M.std(axis=0, keepdims=True) + 1e-10)\n",
    "\n",
    "        # Center and scale y so that ||y||_2^2 = m\n",
    "        y_mean = y.mean()\n",
    "        y_sd = y.std()\n",
    "        y_std = (y - y_mean) / (y_sd + 1e-10)\n",
    "\n",
    "        return M_std, y_std\n",
    "\n",
    "    def _phase1_qrcp(self, M: np.ndarray, k1: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        _, R, piv = linalg.qr(M, mode='economic', pivoting=True)\n",
    "\n",
    "        S1 = piv[:k1]\n",
    "\n",
    "        Q1, R11 = linalg.qr(M[:, S1], mode='economic')\n",
    "\n",
    "        return Q1, R11, S1\n",
    "\n",
    "    def _phase1_partial_qrcp(self, M: np.ndarray, k1: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Phase 1: Highly optimized Partial QRCP (k1 steps only).\n",
    "\n",
    "        Complexity: O(m*n*k1)\n",
    "        \"\"\"\n",
    "         \n",
    "        m, n = M.shape\n",
    "        \n",
    "        # Working copy\n",
    "        A = M.copy()\n",
    "        \n",
    "        # perm tracks the original column indices.\n",
    "        # perm[k] will store the original index of the k-th pivot column.\n",
    "        perm = np.arange(n)\n",
    "        \n",
    "        # Pre-compute the squared L2-norm of each column for pivoting.\n",
    "        # We use squared norms to avoid sqrt.\n",
    "        col_norms_full = np.sum(A**2, axis=0)\n",
    "        col_norms_partial = col_norms_full.copy()\n",
    "        \n",
    "        # Storage for the 'tau' scalars needed to reconstruct Q.\n",
    "        # H_k = I - tau_scalars[k] * v_k * v_k^T\n",
    "        tau_scalars = np.zeros(k1)\n",
    "\n",
    "        # main loop\n",
    "        for k in range(k1):\n",
    "            \n",
    "            # ====================\n",
    "            # 1. COLUMN PIVOTING\n",
    "            # ====================\n",
    "            # Find the column with the maximum remaining norm in the sub-array A[k:, k:].\n",
    "            j_max = k + np.argmax(col_norms_partial[k:])\n",
    "            \n",
    "            if j_max != k:\n",
    "                # Swap the pivot column (j_max) with the current column (k)\n",
    "                A[:, [k, j_max]] = A[:, [j_max, k]]\n",
    "                perm[[k, j_max]] = perm[[j_max, k]]\n",
    "                col_norms_full[[k, j_max]] = col_norms_full[[j_max, k]]\n",
    "                col_norms_partial[[k, j_max]] = col_norms_partial[[j_max, k]]\n",
    "            \n",
    "            # ========================================\n",
    "            # 2. HOUSEHOLDER QR STEP (on column k)\n",
    "            # ========================================\n",
    "            \n",
    "            # Get the k-th column vector starting from the diagonal.\n",
    "            x_k = A[k:m, k]\n",
    "            norm_x_k = np.linalg.norm(x_k)\n",
    "\n",
    "            if norm_x_k < 1e-14:\n",
    "                # This column is already (numerically) zero.\n",
    "                # No reflection needed.\n",
    "                tau_scalars[k] = 0\n",
    "                continue\n",
    "            \n",
    "            # 'sigma_k' is the target value for the first element,\n",
    "            # sign((x_k)_1) * ||x_k||.\n",
    "            sigma_k = -np.sign(x_k[0]) * norm_x_k if x_k[0] != 0 else -norm_x_k\n",
    "            \n",
    "            # --- Calculate the LAPACK-style Householder vector 'v' and 'tau' ---\n",
    "            \n",
    "            # 1. u_k = x_k - sigma_k * e_1\n",
    "            u_0 = x_k[0] - sigma_k\n",
    "            u_tail = x_k[1:]\n",
    "            \n",
    "            # 2. tau_k = -u_0 / sigma_k\n",
    "            tau_k = -u_0 / sigma_k\n",
    "            tau_scalars[k] = tau_k # Store for Q reconstruction\n",
    "            \n",
    "            # 3. v_k = u_k / u_0 = [1, u_tail / u_0]^T\n",
    "            v_tail = u_tail / u_0 if u_0 != 0 else u_tail # Avoid division by zero\n",
    "\n",
    "            # Apply the reflection H_k to all remaining columns (k+1 to n)\n",
    "            # A_sub = (I - tau_k * v_k * v_k^T) @ A_sub\n",
    "            if k < n - 1:\n",
    "                A_sub = A[k:m, k+1:n]\n",
    "                A_sub_head = A_sub[0, :]     # First row of the submatrix\n",
    "                A_sub_tail = A_sub[1:, :]    # Rest of the submatrix\n",
    "                \n",
    "                # w = (v_k^T @ A_sub)\n",
    "                #   = (v_k[0] * A_sub_head) + (v_tail^T @ A_sub_tail)\n",
    "                #   = (1 * A_sub_head) + (v_tail^T @ A_sub_tail)\n",
    "                w = A_sub_head + (v_tail @ A_sub_tail)\n",
    "                \n",
    "                # A_sub = A_sub - tau_k * v_k * w^T\n",
    "                A[k, k+1:n] -= tau_k * w              # Update head (v_k[0]=1)\n",
    "                A[k+1:m, k+1:n] -= tau_k * np.outer(v_tail, w) # Update tail\n",
    "            \n",
    "            # Store R_kk and the Householder vector v_tail\n",
    "            # directly into the matrix A.\n",
    "            A[k, k] = sigma_k      # R's diagonal element\n",
    "            A[k+1:m, k] = v_tail # The tail of the vector v_k\n",
    "            \n",
    "            # ===================================\n",
    "            # 3. UPDATE COLUMN NORMS (downdate)\n",
    "            # ===================================\n",
    "            # This is the O(n) part.\n",
    "            # Use Pythagoras to update the remaining norm of each column after the reflection.\n",
    "            # new_tail_norm^2 = total_norm^2 - new_head_val^2\n",
    "            if k < n - 1:\n",
    "                for j in range(k+1, n):\n",
    "                    # temp = 1 - (A[k, j] / col_norms_partial[j])**2\n",
    "                    temp_ratio = A[k, j] / col_norms_partial[j] if col_norms_partial[j] > 0 else 0\n",
    "                    temp_ratio = max(0, (1 - temp_ratio) * (1 + temp_ratio)) # (1-t^2)\n",
    "                    \n",
    "                    # col_norms_partial[j] = col_norms_partial[j] * sqrt(temp_ratio)\n",
    "                    col_norms_partial[j] *= np.sqrt(temp_ratio)\n",
    "                    \n",
    "                    # Failsafe: Recompute norm if numerical error accumulates\n",
    "                    if col_norms_partial[j] < 0.1 * np.sqrt(col_norms_full[j]):\n",
    "                        col_norms_partial[j] = np.linalg.norm(A[k+1:m, j])\n",
    "                        col_norms_full[j] = col_norms_partial[j]**2\n",
    "        \n",
    "        # ====================================================================\n",
    "        # 4. EXTRACT RESULTS (Q, R, S)\n",
    "        # ====================================================================\n",
    "        \n",
    "        # R11 is the upper-triangular k1 x k1 block of A\n",
    "        R11 = np.triu(A[:k1, :k1])\n",
    "\n",
    "        Q1 = np.eye(m, k1)\n",
    "        \n",
    "        for k in range(k1-1, -1, -1):\n",
    "            tau_k = tau_scalars[k] # Get the stored scalar\n",
    "            \n",
    "            if tau_k != 0:\n",
    "                # Reconstruct v_k = [1, v_tail]^T\n",
    "                v = np.zeros(m - k)\n",
    "                v[0] = 1\n",
    "                v[1:] = A[k+1:m, k] # Get the stored v_tail\n",
    "                \n",
    "                # Apply the transformation:\n",
    "                # Q1[k:, k:] = H_k @ Q1[k:, k:]\n",
    "                #            = (I - tau_k * v * v^T) @ Q1[k:, k:]\n",
    "                w = tau_k * (v @ Q1[k:, k:])\n",
    "                Q1[k:, k:] -= np.outer(v, w)\n",
    "        \n",
    "        # S1: The original indices of the first k1 pivot columns\n",
    "        S1 = perm[:k1]\n",
    "        \n",
    "        return Q1, R11, S1\n",
    "    \n",
    "    def _phase2_tprs(self, M: np.ndarray, y: np.ndarray, Q1: np.ndarray,\n",
    "                    S1: np.ndarray, k1: int, delta: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Phase 2: Target-Projected Residual Sampling with one-step \n",
    "        \"\"\"\n",
    "        m, n = M.shape\n",
    "        k2 = self.k - k1\n",
    "        # ==========\n",
    "        # 1. TPRS\n",
    "        # ==========\n",
    "        # Target residual\n",
    "        r_y = y - Q1 @ (Q1.T @ y)\n",
    "\n",
    "        # Precompute residualized features\n",
    "        Q1_T_M = Q1.T @ M\n",
    "\n",
    "        # b_j = \\|x_j\\|_2^2 - \\|Q_1^Tx_j\\|_2^2\n",
    "        b = np.sum(M**2, axis=0) - np.sum(Q1_T_M**2, axis=0)\n",
    "        b = np.maximum(b, self.epsilon) # Prevent 0\n",
    "\n",
    "        # s_j = r_y^TP_\\perpx_j = r_y^Tx_j\n",
    "        s = r_y @ M\n",
    "\n",
    "        # Supervised score a_j := s_j^2 / (b_j + \\epsilon)\n",
    "        if self.supervised:\n",
    "            a = s**2 / (b + self.epsilon)\n",
    "        else:\n",
    "            a = b\n",
    "        # ==================================================\n",
    "        # 2. Greedy Oversampling with one-step deflation\n",
    "        # ==================================================\n",
    "                \n",
    "        # Initialize candidate pool\n",
    "        valid_mask = np.ones(n, dtype=bool)\n",
    "        valid_mask[S1] = False\n",
    "\n",
    "        # List for chosen columns in phase 2\n",
    "        S2_prime = []\n",
    "\n",
    "        for _ in range(k2+delta):\n",
    "            a_masked = np.where(valid_mask, a, -np.inf)\n",
    "\n",
    "            # j* = argmax a_j\n",
    "            j_star = np.argmax(a_masked)\n",
    "\n",
    "            # Add it to the answer\n",
    "            S2_prime.append(j_star)\n",
    "\n",
    "            # Update for the next iteration\n",
    "            valid_mask[j_star] = False\n",
    "\n",
    "            # ----- One-Step Deflation ----- #\n",
    "\n",
    "            # Choose the column for the chosen j\n",
    "            x_j = M[:, j_star]\n",
    "\n",
    "            # Get P_\\perp x_j\n",
    "            P_perp_x = x_j - Q1 @ (Q1.T @ x_j)\n",
    "\n",
    "            # Normalize it\n",
    "            norm_P_perp_x = np.linalg.norm(P_perp_x)\n",
    "\n",
    "            if norm_P_perp_x > 1e-10:\n",
    "\n",
    "                # New direction (contribution) of x_j\n",
    "                u = P_perp_x / norm_P_perp_x\n",
    "\n",
    "                # The Magnitude * direction = The new contribution of x_j\n",
    "                g = u.T @ M\n",
    "\n",
    "                # The new columns contribution to the label\n",
    "                alpha = u.T @ r_y\n",
    "\n",
    "                # Decrease the residual\n",
    "                r_y -= alpha * u\n",
    "\n",
    "                # Decrease the correlation of each columns\n",
    "                s -= alpha * g\n",
    "\n",
    "                if self.supervised:\n",
    "                    a = s**2 / (b+self.epsilon)\n",
    "\n",
    "                else:\n",
    "                    a = b     \n",
    "\n",
    "        return np.array(S2_prime, dtype=int)\n",
    "\n",
    "    def _phase3_gpp(self, M: np.ndarray, y: np.ndarray,\n",
    "                   S_tmp: np.ndarray, k:int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Phase 3: Geometry-Predictive Pruning to size k.\n",
    "        \"\"\"\n",
    "        # Working copy\n",
    "        S_current = S_tmp.copy()\n",
    "\n",
    "        # Measure delta that we are going to prune\n",
    "        delta = len(S_tmp) - k\n",
    "\n",
    "        for _ in range(delta):\n",
    "            C = M[:, S_current]\n",
    "\n",
    "            # QR Decomposition\n",
    "            # mode='economic' --> thin QR (Q = m*n, R = n*n)\n",
    "            Q, R = linalg.qr(C, mode='economic')\n",
    "\n",
    "            # Compute beta (R^-1(Q^T y)) --> \"Predictive\"\n",
    "            # We don't get inverse, we use \"back substitution\" (solve_triangular)\n",
    "            # \\beta = min\\|C\\beta-y\\|_2^2\n",
    "            # Least Square Problem\n",
    "            # Equation: C\\beta = y\n",
    "            # Solution: \\beta = (C^TC)^-1C^Ty\n",
    "            # \\beta = (R^TQ^TQ^R)^-1R^TQ^Ty = (R^TR)^-1R^TQ^Ty = R^-1Q^Ty\n",
    "            beta = linalg.solve_triangular(R, Q.T @ y, lower=False)\n",
    "\n",
    "            # Compute r_i --> \"Geometric Redundancy\" (Numerical Instability)\n",
    "            # VIF (Variance Inflaction Factor) = 1/ (1 - R_i)\n",
    "            # C = QR --> G = C^TC = R^TR\n",
    "            # r_i = \\|R^-Te_i\\|_2^2 = (R^-Te_i)^T(R^-Te_i) = e_i^T(R^-1R^-T)e_i = e_i^T(R^TR)^-1e_i = [(C^TC)^-1]_ii\n",
    "            # By block matrix inversion --> (G^-1)_ii = 1 / c_i^Tc_i(1-R_i^2) = 1/\\|c_i\\|_2^2 \\times VIF_i\n",
    "            R_inv_T = linalg.solve_triangular(R, np.eye(len(S_current)), trans='T', lower=False)\n",
    "            r_i = np.sum(R_inv_T**2, axis=0)\n",
    "\n",
    "            # Compute drop scores: d_i = r_i / (beta_i^2 + epsilon)\n",
    "            d_i = r_i / (beta**2 + self.epsilon)\n",
    "\n",
    "            # Remove worst feature\n",
    "            i_star = np.argmax(d_i)\n",
    "            S_current = np.delete(S_current, i_star) # Delete the column\n",
    "\n",
    "        return S_current\n",
    "        \n",
    "    def transform(self, M: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Select features from M.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.selected_features_ is None:\n",
    "            raise ValueError(\"Must fit before transform\")\n",
    "            \n",
    "        return M[:, self.selected_features_]  \n",
    "        \n",
    "    def fit_transform(self, M: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Fit and transform in one step.\n",
    "        \"\"\"\n",
    "        return self.fit(M, y).transform(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Baseline Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoSelector:\n",
    "    def __init__(self, k: int):\n",
    "        self.k = k\n",
    "        self.selected_features_ = None\n",
    "        self.runtime_ = 0.0\n",
    "    def fit(self, M: np.ndarray, y: np.ndarray):\n",
    "        t = time.time()\n",
    "        model = LassoCV(cv=5, max_iter=20000, n_jobs=-1)\n",
    "        model.fit(M, y)\n",
    "        coef_abs = np.abs(model.coef_)\n",
    "        self.selected_features_ = np.argsort(coef_abs)[-self.k:]\n",
    "        self.runtime_ = time.time() - t\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        if self.selected_features_ is None:\n",
    "            raise ValueError(\"Must fit before transform.\")\n",
    "        return np.asarray(X)[:, self.selected_features_]\n",
    "\n",
    "    def fit_transform(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "\n",
    "class FullQRCPSelector:\n",
    "    def __init__(self, k: int):\n",
    "        self.k = k\n",
    "        self.selected_features_ = None\n",
    "        self.runtime_ = 0.0\n",
    "    def fit(self, M: np.ndarray):\n",
    "        t = time.time()\n",
    "        _, _, piv = linalg.qr(M, mode='economic', pivoting=True)\n",
    "        self.selected_features_ = piv[:self.k]\n",
    "        self.runtime_ = time.time() - t\n",
    "        return self\n",
    "\n",
    "\n",
    "class ARSQRCPSelector:\n",
    "    \"\"\"Our unsupervised variant (TAAQ with supervised=False).\"\"\"\n",
    "    def __init__(self, k: int):\n",
    "        self.k = k\n",
    "        self.selected_features_ = None\n",
    "        self.runtime_ = 0.0\n",
    "    def fit(self, M: np.ndarray):\n",
    "        st = time.time()\n",
    "        model = TAAQ(k=self.k, supervised=False)\n",
    "        model.fit(M, None)\n",
    "        self.selected_features_ = model.selected_features_\n",
    "        self.runtime_ = model.runtime_['total']\n",
    "        return self\n",
    "    \n",
    "class CorrelationSelector: \n",
    "    \"\"\"\n",
    "    Feature selector based on absolute correlation with the target variable. \n",
    "    Supports top-k or threshold-based selection.\n",
    "    \"\"\"    \n",
    "\n",
    "    def __init__(self, method = 'pearson', k = None, threshold = None, target_encode = True, verbose = False):\n",
    "        self.method = method\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.target_encode = target_encode\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: dataframe (n_samples, n_features)\n",
    "        Y: series (n_samples)\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        if isinstance(y, pd.Series):\n",
    "            y_name = y.name\n",
    "        else:\n",
    "            y_name = 'target'\n",
    "            y = pd.Series(y, name = y_name)\n",
    "\n",
    "        if self.target_encode and not np.issubdtype(y.dtype, np.number):\n",
    "            y = LabelEncoder().fit_transform(y)\n",
    "            y = pd.Series(y, name = y_name)\n",
    "    \n",
    "        # Compute correlations\n",
    "        corr_series = X.corrwith(y, method=self.method)\n",
    "        self.correlations_ = corr_series.fillna(0).to_numpy()\n",
    "        self.feature_names_in_ = X.columns.to_numpy()\n",
    "\n",
    "        # Select features\n",
    "        if self.k is not None:\n",
    "            order = np.argsort(-np.abs(self.correlations_))\n",
    "            self.support_idx_ = np.sort(order[:self.k])\n",
    "        else:\n",
    "            thresh = self.threshold if self.threshold is not None else np.median(np.abs(self.correlations_))\n",
    "            self.support_idx_ = np.where(np.abs(self.correlations_) >= thresh)[0]\n",
    "\n",
    "        self.support_ = np.zeros(len(self.feature_names_in_), dtype=bool)\n",
    "        self.support_[self.support_idx_] = True\n",
    "\n",
    "        if self.verbose:\n",
    "            selected = self.feature_names_in_[self.support_idx_]\n",
    "            print(f\"[CorrelationSelector] Selected {len(selected)} features: {list(selected)}\")\n",
    "\n",
    "        self.selected_features_ = self.support_idx_\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Reduce X to selected features.\"\"\"\n",
    "        check_is_fitted(self, \"support_\")\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        return X.iloc[:, self.support_idx_]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "    \n",
    "\n",
    "class RandomForestSelector:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, task='regression', n_estimators=200, random_state=42, k=None, threshold=None, target_encode=True, verbose=False):\n",
    "        self.task = task\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.target_encode = target_encode\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        if isinstance(y, pd.Series):\n",
    "            y_name = y.name\n",
    "        else:\n",
    "            y_name = 'target'\n",
    "            y = pd.Series(y, name=y_name)\n",
    "    \n",
    "        if self.target_encode and not np.issubdtype(y.dtype, np.number):\n",
    "            y = LabelEncoder().fit_transform(y)\n",
    "            y = pd.Series(y, name = y_name)\n",
    "\n",
    "        if self.task == 'classification':\n",
    "            model = RandomForestClassifier(n_estimators=self.n_estimators, random_state=self.random_state, n_jobs=-1)\n",
    "        else:\n",
    "            model = RandomForestRegressor(n_estimators=self.n_estimators, random_state=self.random_state, n_jobs=-1)\n",
    "\n",
    "        model.fit(X, y)\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "        self.importances_ = importances\n",
    "        self.feature_names_in_ = X.columns.to_numpy()\n",
    "\n",
    "        # Select features\n",
    "        if self.k is not None:\n",
    "            order = np.argsort(-importances)\n",
    "            self.support_idx_ = np.sort(order[:self.k])\n",
    "        else:\n",
    "            thresh = self.threshold if self.threshold is not None else np.median(importances)\n",
    "            self.support_idx_ = np.where(importances >= thresh)[0]\n",
    "\n",
    "        self.support_ = np.zeros(len(self.feature_names_in_), dtype=bool)\n",
    "        self.support_[self.support_idx_] = True\n",
    "        self.selected_features_ = self.support_idx_\n",
    "\n",
    "        if self.verbose:\n",
    "            selected = self.feature_names_in_[self.support_idx_]\n",
    "            print(f\"[RandomForestSelector] Selected {len(selected)} features: {list(selected)}\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        reduce X to selected features\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'support_')\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        return X.iloc[:, self.support_idx_].copy()\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)\n",
    "    \n",
    "\n",
    "class ElasticNetSelector:\n",
    "    \"\"\"\n",
    "    Elastic Net–based feature selector.\n",
    "\n",
    "    Fits an ElasticNet model and selects the top-k features by\n",
    "    absolute coefficient magnitude.\n",
    "\n",
    "    Matching API with QRCP + MRMR:\n",
    "        - selected_features_\n",
    "        - runtime_ dict\n",
    "        - fit / transform / fit_transform\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k: int, alpha: float = 1.0, l1_ratio: float = 0.5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of features to select.\n",
    "\n",
    "        alpha : float\n",
    "            Regularization strength for ElasticNet.\n",
    "\n",
    "        l1_ratio : float\n",
    "            Mixing parameter between L1 and L2 (0 = pure L2, 1 = pure L1).\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "\n",
    "        self.model_ = None\n",
    "        self.selected_features_ = None\n",
    "        self.runtime_ = {}  # for consistency with QRCP and MRMR\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> \"ElasticNetSelector\":\n",
    "        \"\"\"\n",
    "        Fit ElasticNet and choose the top-k important features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "        y : np.ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # STEP 1: Fit ElasticNet\n",
    "        t_enet_start = time.time()\n",
    "        enet = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], cv=5)\n",
    "        enet.fit(X, y)\n",
    "        self.runtime_[\"elastic_net_fit\"] = time.time() - t_enet_start\n",
    "\n",
    "        self.model_ = enet\n",
    "\n",
    "        # STEP 2: Rank features by coefficient magnitude\n",
    "        coefs = np.abs(enet.coef_)\n",
    "        ranked = np.argsort(coefs)[::-1]   # descending order\n",
    "        self.selected_features_ = ranked[: self.k]\n",
    "\n",
    "        # STEP 3: Total runtime\n",
    "        self.runtime_[\"total\"] = time.time() - start_time\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Return X with only the selected features.\n",
    "        \"\"\"\n",
    "        if self.selected_features_ is None:\n",
    "            raise ValueError(\"Must call fit() before transform()\")\n",
    "\n",
    "        return X[:, self.selected_features_]\n",
    "\n",
    "    def fit_transform(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        return self.fit(X, y).transform(X)\n",
    "    \n",
    "\n",
    "class MRMRSelector:\n",
    "    \"\"\"\n",
    "    Minimum Redundancy Maximum Relevance (mRMR) feature selector.\n",
    "\n",
    "    Wraps mrmr_regression() into a QRCP-style estimator class\n",
    "    with:\n",
    "        - selected_features_\n",
    "        - runtime tracking\n",
    "        - fit / transform / fit_transform API\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k: int):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of features to select.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.selected_features_ = None\n",
    "        self.runtime_ = {}  # for parity with QRCP\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> \"MRMRSelector\":\n",
    "        \"\"\"\n",
    "        Fit the mRMR selector.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray, shape (m, n)\n",
    "            Feature matrix.\n",
    "        y : np.ndarray, shape (m,)\n",
    "            Target vector.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : MRMRSelector\n",
    "            Fitted selector with selected_features_ populated.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Convert input to pandas (required by mrmr)\n",
    "        X_df = pd.DataFrame(X)\n",
    "        y_sr = pd.Series(y)\n",
    "\n",
    "        # Run mRMR\n",
    "        t_mrmr_start = time.time()\n",
    "        idxs = mrmr_regression(\n",
    "            X_df, \n",
    "            y_sr, \n",
    "            K=self.k,\n",
    "            show_progress=False\n",
    "        )\n",
    "        self.runtime_[\"mrmr_selection\"] = time.time() - t_mrmr_start\n",
    "\n",
    "        # mrmr_regression returns a list of column indices\n",
    "        self.selected_features_ = np.array(idxs, dtype=int)\n",
    "\n",
    "        # Total runtime\n",
    "        self.runtime_[\"total\"] = time.time() - start_time\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Select only the chosen mRMR features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_transformed : np.ndarray, shape (m, k)\n",
    "        \"\"\"\n",
    "        if self.selected_features_ is None:\n",
    "            raise ValueError(\"Must call fit() before transform()\")\n",
    "\n",
    "        return X[:, self.selected_features_]\n",
    "\n",
    "    def fit_transform(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convenience method.\n",
    "        \"\"\"\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluation Framework (Metric, Plotting, Tracks)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(scores: Dict[str, float], title: str, ylabel: str):\n",
    "    labels = list(scores.keys())\n",
    "    vals = [scores[k] for k in labels]\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.bar(labels, vals)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_supervised_track(X: np.ndarray, y: np.ndarray, k: int, n_splits: int = 3):\n",
    "    print(\"\\n\" + \"=\"*68)\n",
    "    print(\"SUPERVISED TRACK\")\n",
    "    print(\"=\"*68)\n",
    "\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    ys = (y - y.mean()) / (y.std() + 1e-12)\n",
    "\n",
    "    methods = {\n",
    "        \"TAAQ\": TAAQ(k=k, k1_fraction=0.5, delta=10, supervised=True),\n",
    "        \"Lasso\": LassoSelector(k=k),\n",
    "        \"Correlation Selector\": CorrelationSelector(method='pearson', k=5, verbose = False),\n",
    "        \"Random Forest Selector\": RandomForestSelector(task='regression', k=10, verbose=False),\n",
    "        \"Elastic Net Selector\": ElasticNetSelector(k=k, alpha=1.0, l1_ratio=0.5),\n",
    "        \"mRMR\": MRMRSelector(k=k),\n",
    "    }\n",
    "     \n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    rows = []\n",
    "    for fold, (tr, te) in enumerate(kf.split(Xs)):\n",
    "        Xtr, Xte = Xs[tr], Xs[te]\n",
    "        ytr, yte = ys[tr], ys[te]\n",
    "        print(f\"\\n  Fold {fold+1}/{n_splits}\")\n",
    "        for name, meth in methods.items():\n",
    "            # Title of experiment\n",
    "            print(\"=\"*68) \n",
    "            if name != \"TAAQ\":\n",
    "                print(f\"Comparing: TAAQ vs {name}\")\n",
    "            print(\"=\"*68)   \n",
    "\n",
    "            t = time.time()\n",
    "            if isinstance(meth, TAAQ):\n",
    "                meth.fit(Xtr, ytr)\n",
    "            else:\n",
    "                meth.fit(Xtr, ytr)\n",
    "            S = meth.selected_features_\n",
    "            # Ridge on selected features (held-out test)\n",
    "            mdl = Ridge(alpha=1.0).fit(Xtr[:, S], ytr)\n",
    "            y_pred = mdl.predict(Xte[:, S])\n",
    "            r2 = r2_score(yte, y_pred)\n",
    "            rmse = float(np.sqrt(mean_squared_error(yte, y_pred)))\n",
    "            runtime = time.time() - t\n",
    "            rows.append(dict(method=name, fold=fold, r2=r2, rmse=rmse, runtime=runtime, k=len(S)))\n",
    "            print(f\"    - {name:6s} | R²={r2: .3f} | RMSE={rmse: .3f} | k={len(S)}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    summ = df.groupby(\"method\")[[\"r2\", \"rmse\", \"runtime\"]].mean().round(4)\n",
    "    print(\"\\nSupervised summary (mean over folds):\\n\", summ)\n",
    "\n",
    "    bar_plot(summ[\"r2\"].to_dict(), \"Supervised: R² (higher is better)\", \"R²\")\n",
    "    bar_plot(summ[\"rmse\"].to_dict(), \"Supervised: RMSE (lower is better)\", \"RMSE\")\n",
    "    bar_plot(summ[\"runtime\"].to_dict(), \"Supervised: Runtime (s)\", \"seconds\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Data Generators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_synthetic(m=350, n=120, k_true=25, noise=10, seed=42):\n",
    "    X, y = make_regression(n_samples=m, n_features=n, n_informative=k_true,\n",
    "                           noise=noise, random_state=seed)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TAAQ MINIMAL EXPERIMENTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 1) Synthetic: both tracks\n",
    "    print(\"\\n[Dataset] Synthetic linear (m=350, n=120)\")\n",
    "    Xs, ys = dataset_synthetic()\n",
    "    k = 35\n",
    "    run_supervised_track(Xs, ys, k=k, n_splits=3)\n",
    "\n",
    "    print(\"\\nAll done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Quick Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Main Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
